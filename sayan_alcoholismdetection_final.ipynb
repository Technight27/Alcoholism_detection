{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VeGsqosyu2-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "61686d69-6f20-45a4-c6ff-cf9bef96d544"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d7743ef-27aa-47e3-8e90-048b8dd7322f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d7743ef-27aa-47e3-8e90-048b8dd7322f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Alcoholism_eeg_dataset .csv to Alcoholism_eeg_dataset .csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Final Code for alcoholism paper  # use this code\n",
        "# Designing of the attention-based model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, Dense, Attention, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Alcoholism_eeg_dataset .csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.drop(columns=['Class']).values\n",
        "y = data['Class'].values\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, Attention, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=25)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define CNN-BiLSTM with attention model\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "conv_layer1 = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)\n",
        "conv_layer2 = Conv1D(filters=64, kernel_size=3, activation='relu')(conv_layer1)\n",
        "conv_layer3 = Conv1D(filters=64, kernel_size=3, activation='relu')(conv_layer2)\n",
        "bi_lstm_layer1 = Bidirectional(LSTM(64, return_sequences=True))(conv_layer3)\n",
        "bi_lstm_layer2 = Bidirectional(LSTM(64, return_sequences=True))(bi_lstm_layer1)\n",
        "attention_layer = Attention()([bi_lstm_layer2, bi_lstm_layer2])\n",
        "flatten_layer = Flatten()(attention_layer)\n",
        "output_layer = Dense(y_train.shape[1], activation='softmax')(flatten_layer)\n",
        "\n",
        "model = Sequential(name='Alco-net')\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape data for Conv1D\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Train the model and store the history\n",
        "history = model.fit(X_train_cnn, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_cnn)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "class_report = classification_report(y_true_classes, y_pred_classes)\n",
        "print(\"Accuracy Score\",accuracy_score(y_pred_classes,y_true_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FbUMFQJOf74z",
        "outputId": "3d1f2cfe-efd5-474e-96fb-ea2684f79955"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 19s 110ms/step - loss: 0.6629 - accuracy: 0.5702 - val_loss: 0.4084 - val_accuracy: 0.8110\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 0.3173 - accuracy: 0.8534 - val_loss: 0.1699 - val_accuracy: 0.9268\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 0.1565 - accuracy: 0.9427 - val_loss: 0.1140 - val_accuracy: 0.9512\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 3s 84ms/step - loss: 0.1345 - accuracy: 0.9435 - val_loss: 0.1636 - val_accuracy: 0.9360\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 3s 83ms/step - loss: 0.1307 - accuracy: 0.9504 - val_loss: 0.1073 - val_accuracy: 0.9573\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 3s 61ms/step - loss: 0.0885 - accuracy: 0.9695 - val_loss: 0.0540 - val_accuracy: 0.9756\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 0.0703 - accuracy: 0.9710 - val_loss: 0.0499 - val_accuracy: 0.9695\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 2s 58ms/step - loss: 0.0357 - accuracy: 0.9870 - val_loss: 0.0797 - val_accuracy: 0.9787\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 3s 83ms/step - loss: 0.0465 - accuracy: 0.9847 - val_loss: 0.0706 - val_accuracy: 0.9756\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0242 - val_accuracy: 0.9909\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 0.0336 - accuracy: 0.9878 - val_loss: 0.0357 - val_accuracy: 0.9878\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 2s 58ms/step - loss: 0.0252 - accuracy: 0.9893 - val_loss: 0.0166 - val_accuracy: 0.9909\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0496 - val_accuracy: 0.9878\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 3s 82ms/step - loss: 0.0647 - accuracy: 0.9763 - val_loss: 0.0385 - val_accuracy: 0.9970\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 3s 84ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.0532 - val_accuracy: 0.9817\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 0.0186 - accuracy: 0.9916 - val_loss: 0.0557 - val_accuracy: 0.9878\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0715 - val_accuracy: 0.9787\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.0367 - val_accuracy: 0.9848\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 3s 82ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.0204 - val_accuracy: 0.9909\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 3s 79ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0612 - val_accuracy: 0.9817\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9909\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0184 - val_accuracy: 0.9939\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0386 - val_accuracy: 0.9848\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 4s 88ms/step - loss: 0.0283 - accuracy: 0.9885 - val_loss: 0.1573 - val_accuracy: 0.9634\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0371 - val_accuracy: 0.9848\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 6.0949e-04 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9817\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 3s 61ms/step - loss: 1.1137e-04 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9878\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 6.1783e-05 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9878\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 4s 95ms/step - loss: 4.5552e-05 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9848\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 3.6586e-05 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9878\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 2.9985e-05 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9878\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 2.5387e-05 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9848\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 2.1403e-05 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9878\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 4s 101ms/step - loss: 1.8663e-05 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9878\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 3s 67ms/step - loss: 1.6384e-05 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9878\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 1.4763e-05 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9878\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 1.3133e-05 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9878\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 1.1872e-05 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9878\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 4s 102ms/step - loss: 1.0747e-05 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9878\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 9.8889e-06 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9878\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 9.0538e-06 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9878\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 8.3540e-06 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9878\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 7.7188e-06 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9878\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 7.1733e-06 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9878\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 6.7004e-06 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9878\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 6.2304e-06 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9878\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 5.8321e-06 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9878\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 5.4802e-06 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9878\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 4s 102ms/step - loss: 5.1495e-06 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9878\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 4.8693e-06 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9878\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 4.5812e-06 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9878\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 4.3305e-06 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9878\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 4.1004e-06 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9878\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 4s 96ms/step - loss: 3.8823e-06 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9878\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 3.6883e-06 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9878\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 3.5033e-06 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9878\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 3.3342e-06 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9878\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 3.1747e-06 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9878\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 4s 95ms/step - loss: 3.0262e-06 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9878\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 2.8902e-06 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9878\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 2.7624e-06 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9878\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 2.6362e-06 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9878\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 3s 67ms/step - loss: 2.5295e-06 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9878\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 4s 93ms/step - loss: 2.4229e-06 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9878\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 2.3231e-06 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9878\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 3s 61ms/step - loss: 2.2217e-06 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9878\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 2.1351e-06 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9878\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 3s 77ms/step - loss: 2.0494e-06 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9878\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 4s 88ms/step - loss: 1.9649e-06 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9878\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 2s 58ms/step - loss: 1.8882e-06 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9878\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 1.8176e-06 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9878\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 1.7504e-06 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9878\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 1.6858e-06 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9878\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 4s 87ms/step - loss: 1.6222e-06 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9878\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 1.5657e-06 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9878\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 1.5073e-06 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9878\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.4525e-06 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9878\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 3s 86ms/step - loss: 1.4021e-06 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9878\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 1.3511e-06 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9878\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.3035e-06 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9878\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.2594e-06 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9878\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 1.2185e-06 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9878\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 4s 92ms/step - loss: 1.1783e-06 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9878\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 1.1386e-06 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9878\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 1.1004e-06 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9878\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.0655e-06 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9878\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.0312e-06 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9878\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 4s 103ms/step - loss: 9.9789e-07 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9878\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 9.6540e-07 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9878\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 9.3674e-07 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9878\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 9.0634e-07 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9878\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 3s 61ms/step - loss: 8.7823e-07 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9878\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 8.4956e-07 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9878\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 8.2426e-07 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9878\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 7.9815e-07 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9878\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 7.7604e-07 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9878\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 7.5201e-07 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9878\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 4s 98ms/step - loss: 7.2999e-07 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9878\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 7.0952e-07 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9878\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 6.8768e-07 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9878\n",
            "13/13 [==============================] - 3s 16ms/step\n",
            "Accuracy Score 0.9951219512195122\n",
            "Confusion Matrix:\n",
            "[[206   2]\n",
            " [  0 202]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       208\n",
            "           1       0.99      1.00      1.00       202\n",
            "\n",
            "    accuracy                           1.00       410\n",
            "   macro avg       1.00      1.00      1.00       410\n",
            "weighted avg       1.00      1.00      1.00       410\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAYUlEQVR4nO3dd3hU1b7G8XcCZEJJIUCa0pEmSNUYUSCCVBEECyIaEBE9gEqkmHNUICpBQEAQQT0KSLELKlYgFNHQjQhHkVBEDyQ0Q0yAISRz//Ayx2EFSCCTGdjfz332c0/27Fn7N3OuPr/7rrXX2JxOp1MAAADA3/h5uwAAAAD4HppEAAAAGGgSAQAAYKBJBAAAgIEmEQAAAAaaRAAAABhoEgEAAGCgSQQAAICBJhEAAAAGmkQA57Rjxw516NBBwcHBstlsWrx4cbGOv2fPHtlsNs2ZM6dYx72UtW3bVm3btvV2GQAsjiYRuATs3LlTgwYNUq1atRQQEKCgoCC1atVKL730ko4fP+7Re8fFxenHH3/U888/r3nz5qlly5YevV9J6tevn2w2m4KCggr8Hnfs2CGbzSabzaZJkyYVefx9+/ZpzJgxSk1NLYZqAaBklfZ2AQDO7bPPPtOdd94pu92u+++/X40aNdLJkye1Zs0ajRgxQtu2bdNrr73mkXsfP35cKSkp+te//qUhQ4Z45B7Vq1fX8ePHVaZMGY+Mfz6lS5fWsWPH9Omnn+quu+5ye23BggUKCAjQiRMnLmjsffv2aezYsapRo4aaNm1a6Pd9/fXXF3Q/AChONImAD9u9e7d69+6t6tWrKzk5WZGRka7XBg8erLS0NH322Wceu//BgwclSSEhIR67h81mU0BAgMfGPx+73a5WrVrp7bffNprEhQsXqmvXrvrwww9LpJZjx46pXLly8vf3L5H7AcC5MN0M+LAJEyYoOztbb7zxhluDeFqdOnX02GOPuf4+deqUnn32WdWuXVt2u101atTQP//5TzkcDrf31ahRQ7feeqvWrFmj6667TgEBAapVq5beeust1zVjxoxR9erVJUkjRoyQzWZTjRo1JP01TXv6P//dmDFjZLPZ3M4tXbpUN954o0JCQlShQgXVq1dP//znP12vn21NYnJysm666SaVL19eISEh6t69u3766acC75eWlqZ+/fopJCREwcHB6t+/v44dO3b2L/YMffr00RdffKHMzEzXuQ0bNmjHjh3q06ePcf2RI0c0fPhwNW7cWBUqVFBQUJA6d+6sH374wXXNypUrde2110qS+vfv75q2Pv0527Ztq0aNGmnTpk1q3bq1ypUr5/pezlyTGBcXp4CAAOPzd+zYURUrVtS+ffsK/VkBoLBoEgEf9umnn6pWrVq64YYbCnX9gw8+qGeeeUbNmzfXlClT1KZNGyUlJal3797GtWlpabrjjjt0yy236MUXX1TFihXVr18/bdu2TZLUs2dPTZkyRZJ0zz33aN68eZo6dWqR6t+2bZtuvfVWORwOJSYm6sUXX9Rtt92mb7/99pzvW7ZsmTp27KgDBw5ozJgxio+P13fffadWrVppz549xvV33XWX/vzzTyUlJemuu+7SnDlzNHbs2ELX2bNnT9lsNn300UeucwsXLlT9+vXVvHlz4/pdu3Zp8eLFuvXWWzV58mSNGDFCP/74o9q0aeNq2Bo0aKDExERJ0kMPPaR58+Zp3rx5at26tWucw4cPq3PnzmratKmmTp2q2NjYAut76aWXVKVKFcXFxSkvL0+S9Oqrr+rrr7/W9OnTFRUVVejPCgCF5gTgk44ePeqU5OzevXuhrk9NTXVKcj744INu54cPH+6U5ExOTnadq169ulOSc/Xq1a5zBw4ccNrtducTTzzhOrd7926nJOfEiRPdxoyLi3NWr17dqGH06NHOv/9rZcqUKU5JzoMHD5617tP3mD17tutc06ZNnWFhYc7Dhw+7zv3www9OPz8/5/3332/c74EHHnAb8/bbb3dWqlTprPf8++coX7680+l0Ou+44w5nu3btnE6n05mXl+eMiIhwjh07tsDv4MSJE868vDzjc9jtdmdiYqLr3IYNG4zPdlqbNm2ckpyzZs0q8LU2bdq4nfvqq6+ckpzPPfecc9euXc4KFSo4e/Tocd7PCAAXiiQR8FFZWVmSpMDAwEJd//nnn0uS4uPj3c4/8cQTkmSsXWzYsKFuuukm199VqlRRvXr1tGvXrguu+Uyn1zJ+/PHHys/PL9R79u/fr9TUVPXr10+hoaGu89dcc41uueUW1+f8u4cfftjt75tuukmHDx92fYeF0adPH61cuVLp6elKTk5Wenp6gVPN0l/rGP38/vrXZ15eng4fPuyaSt+8eXOh72m329W/f/9CXduhQwcNGjRIiYmJ6tmzpwICAvTqq68W+l4AUFQ0iYCPCgoKkiT9+eefhbr+119/lZ+fn+rUqeN2PiIiQiEhIfr111/dzlerVs0Yo2LFivrjjz8usGLT3XffrVatWunBBx9UeHi4evfurffee++cDePpOuvVq2e81qBBAx06dEg5OTlu58/8LBUrVpSkIn2WLl26KDAwUO+++64WLFiga6+91vguT8vPz9eUKVN01VVXyW63q3LlyqpSpYq2bNmio0ePFvqeV1xxRZEeUpk0aZJCQ0OVmpqqadOmKSwsrNDvBYCiokkEfFRQUJCioqK0devWIr3vzAdHzqZUqVIFnnc6nRd8j9Pr5U4rW7asVq9erWXLlum+++7Tli1bdPfdd+uWW24xrr0YF/NZTrPb7erZs6fmzp2rRYsWnTVFlKRx48YpPj5erVu31vz58/XVV19p6dKluvrqqwudmEp/fT9F8f333+vAgQOSpB9//LFI7wWAoqJJBHzYrbfeqp07dyolJeW811avXl35+fnasWOH2/mMjAxlZma6nlQuDhUrVnR7Evi0M9NKSfLz81O7du00efJk/ec//9Hzzz+v5ORkrVixosCxT9e5fft247Wff/5ZlStXVvny5S/uA5xFnz599P333+vPP/8s8GGf0z744APFxsbqjTfeUO/evdWhQwe1b9/e+E4K27AXRk5Ojvr376+GDRvqoYce0oQJE7Rhw4ZiGx8AzkSTCPiwkSNHqnz58nrwwQeVkZFhvL5z50699NJLkv6aLpVkPIE8efJkSVLXrl2Lra7atWvr6NGj2rJli+vc/v37tWjRIrfrjhw5Yrz39KbSZ27Lc1pkZKSaNm2quXPnujVdW7du1ddff+36nJ4QGxurZ599Vi+//LIiIiLOel2pUqWMlPL999/Xf//7X7dzp5vZghrqoho1apT27t2ruXPnavLkyapRo4bi4uLO+j0CwMViM23Ah9WuXVsLFy7U3XffrQYNGrj94sp3332n999/X/369ZMkNWnSRHFxcXrttdeUmZmpNm3aaP369Zo7d6569Ohx1u1VLkTv3r01atQo3X777Xr00Ud17NgxzZw5U3Xr1nV7cCMxMVGrV69W165dVb16dR04cECvvPKKrrzySt14441nHX/ixInq3LmzYmJiNGDAAB0/flzTp09XcHCwxowZU2yf40x+fn566qmnznvdrbfeqsTERPXv31833HCDfvzxRy1YsEC1atVyu6527doKCQnRrFmzFBgYqPLlyys6Olo1a9YsUl3Jycl65ZVXNHr0aNeWPLNnz1bbtm319NNPa8KECUUaDwAKxctPVwMohF9++cU5cOBAZ40aNZz+/v7OwMBAZ6tWrZzTp093njhxwnVdbm6uc+zYsc6aNWs6y5Qp46xataozISHB7Rqn868tcLp27Wrc58ytV862BY7T6XR+/fXXzkaNGjn9/f2d9erVc86fP9/YAmf58uXO7t27O6Oiopz+/v7OqKgo5z333OP85ZdfjHucuU3MsmXLnK1atXKWLVvWGRQU5OzWrZvzP//5j9s1p+935hY7s2fPdkpy7t69+6zfqdPpvgXO2ZxtC5wnnnjCGRkZ6SxbtqyzVatWzpSUlAK3rvn444+dDRs2dJYuXdrtc7Zp08Z59dVXF3jPv4+TlZXlrF69urN58+bO3Nxct+uGDRvm9PPzc6akpJzzMwDAhbA5nUVY2Q0AAABLYE0iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIgAAAAw0iQAAADDQJAIAAMBwWf7iStlmQ7xdAgAPObx+urdLAOAh5coU3++dF5Une4fj37/ssbE9iSQRAAAAhssySQQAACgSG7nZmWgSAQAAbN6b6vZVtM0AAAAwkCQCAAAw3WzgGwEAAICBJBEAAIA1iQaSRAAAABhoEgEAAGx+njuKICkpSddee60CAwMVFhamHj16aPv27W7XnDhxQoMHD1alSpVUoUIF9erVSxkZGW7X7N27V127dlW5cuUUFhamESNG6NSpU0WqhSYRAADAR6xatUqDBw/W2rVrtXTpUuXm5qpDhw7KyclxXTNs2DB9+umnev/997Vq1Srt27dPPXv2dL2el5enrl276uTJk/ruu+80d+5czZkzR88880yRarE5nU5nsX0yH8HP8gGXL36WD7h8efVn+aJHeGzs4+smXvB7Dx48qLCwMK1atUqtW7fW0aNHVaVKFS1cuFB33HGHJOnnn39WgwYNlJKSouuvv15ffPGFbr31Vu3bt0/h4eGSpFmzZmnUqFE6ePCg/P39C3VvkkQAAAAPTjc7HA5lZWW5HQ6Ho1BlHT16VJIUGhoqSdq0aZNyc3PVvn171zX169dXtWrVlJKSIklKSUlR48aNXQ2iJHXs2FFZWVnatm1bob8SmkQAAAAPSkpKUnBwsNuRlJR03vfl5+fr8ccfV6tWrdSoUSNJUnp6uvz9/RUSEuJ2bXh4uNLT013X/L1BPP366dcKiy1wAAAAPLgFTkJCguLj493O2e32875v8ODB2rp1q9asWeOp0s6JJhEAAMCD7HZ7oZrCvxsyZIiWLFmi1atX68orr3Sdj4iI0MmTJ5WZmemWJmZkZCgiIsJ1zfr1693GO/308+lrCoPpZgAAAB/ZAsfpdGrIkCFatGiRkpOTVbNmTbfXW7RooTJlymj58uWuc9u3b9fevXsVExMjSYqJidGPP/6oAwcOuK5ZunSpgoKC1LBhw0LXQpIIAADgIwYPHqyFCxfq448/VmBgoGsNYXBwsMqWLavg4GANGDBA8fHxCg0NVVBQkIYOHaqYmBhdf/31kqQOHTqoYcOGuu+++zRhwgSlp6frqaee0uDBg4uUaNIkAgAA+MjP8s2cOVOS1LZtW7fzs2fPVr9+/SRJU6ZMkZ+fn3r16iWHw6GOHTvqlVdecV1bqlQpLVmyRI888ohiYmJUvnx5xcXFKTExsUi1sE8igEsK+yQCly+v7pPY6l8eG/v4t897bGxPIkkEAAAo4tpBK6BJBAAA8JHpZl9C2wwAAAADSSIAAADTzQa+EQAAABhIEgEAAEgSDXwjAAAAMJAkAgAA+PF085lIEgEAAGAgSQQAAGBNooEmEQAAgM20DbTNAAAAMJAkAgAAMN1s4BsBAACAgSQRAACANYkGkkQAAAAYSBIBAABYk2jgGwEAAICBJBEAAIA1iQaaRAAAAKabDXwjAAAAMJAkAgAAMN1sIEkEAACAgSQRAACANYkGvhEAAAAYSBIBAABYk2ggSQQAAICBJBEAAIA1iQaaRAAAAJpEA98IAAAADCSJAAAAPLhiIEkEAACAgSQRAACANYkGvhEAAAAYSBIBAABYk2ggSQQAAICBJBEAAIA1iQaaRAAAAKabDbTNAAAAMJAkAgAAy7ORJBpIEgEAAGAgSQQAAJZHkmgiSQQAAICBJBEAAIAg0UCSCAAAAANNIgAAsDybzeaxo6hWr16tbt26KSoqSjabTYsXLy5UrRMnTnRdU6NGDeP18ePHF6kOppsBAIDl+dKDKzk5OWrSpIkeeOAB9ezZ03h9//79bn9/8cUXGjBggHr16uV2PjExUQMHDnT9HRgYWKQ6aBIBAAB8SOfOndW5c+ezvh4REeH298cff6zY2FjVqlXL7XxgYKBxbVEw3QwAACzPk9PNDodDWVlZbofD4SiWujMyMvTZZ59pwIABxmvjx49XpUqV1KxZM02cOFGnTp0q0tg0iQAAAB6UlJSk4OBgtyMpKalYxp47d64CAwONaelHH31U77zzjlasWKFBgwZp3LhxGjlyZJHGZroZAABYnifXJCYkJCg+Pt7tnN1uL5ax33zzTd17770KCAhwO//3+11zzTXy9/fXoEGDlJSUVOh70yQCAAB4kN1uL7am8O+++eYbbd++Xe++++55r42OjtapU6e0Z88e1atXr1Dj0yQCAAD4zsPNhfbGG2+oRYsWatKkyXmvTU1NlZ+fn8LCwgo9Pk0iAACAD8nOzlZaWprr7927dys1NVWhoaGqVq2aJCkrK0vvv/++XnzxReP9KSkpWrdunWJjYxUYGKiUlBQNGzZMffv2VcWKFQtdB00iAACwPF/aJ3Hjxo2KjY11/X16fWFcXJzmzJkjSXrnnXfkdDp1zz33GO+32+165513NGbMGDkcDtWsWVPDhg0z1kWej83pdDov/GP4prLNhni7BAAecnj9dG+XAMBDypXxXqMWcu98j42duaCvx8b2JJJEAABgeb6UJPoKmkQAAGB5NIkmNtMGAACAgSQRAABYHkmiiSQRAAAABpJEAAAAgkQDSSIAAAAMJIkAAMDyWJNoIkkEAACAgSQRAABYHkmiiSYRAABYHk2iielmAAAAGEgSAQAACBINJIkAAAAwkCQCAADLY02iiSQRAAAABpJEAABgeSSJJpJEAAAAGEgSAQCA5ZEkmmgSAQCA5dEkmphuBgAAgIEkEQAAgCDRQJIIAAAAA0kiAACwPNYkmkgSAQAAYCBJBAAAlkeSaCJJBAAAgIEkEQAAWB5JookmEQAAgB7RwHQzAAAADCSJAADA8phuNpEkAgAAwECSCAAALI8k0USSCAAAAANJInzO8Ac6qMfNTVS3RriOO3K17odd+tdLH2vHrwdc19j9S2t8fE/d2bGF7P6ltSzlJz027l0dOPKn21h9u0Xr0b4366rqYcrKOaGPln6vYePfK+mPBKAI3nj9VSUvW6o9u3fJHhCgJk2b6bFhT6hGzVreLg2XMZJEE0kifM5Nzeto1rur1eb+Sbr1kZdVunQpLZk5ROUC/F3XTBjeS11bN9K9I99QhwenKrJKsN558UG3cR7te7PGDummF2cvVfM7nlfXh6drWcpPJf1xABTR5o0bdPc9ffTWwnc187U3dSr3lB556EEdP3bM26UBlmJzOp1ObxdR3Mo2G+LtElCMKlesoN+Sx6v9gCn6dvNOBVUI0G/J49Xvn3O0aFmqJKlujXD9sOhptbl/ktb/uEchgWW186vn1evxWVq5/hfvfgAUq8Prp3u7BJSwI0eOqF3rG/TvOfPUouW13i4HHlSujPfSvJqPf+axsXdP7eqxsT3Jq9PNhw4d0ptvvqmUlBSlp6dLkiIiInTDDTeoX79+qlKlijfLg48IqhAgSfrj6F8pQrMG1eRfprSS1253XfPLngzt3X9E0dfU1Pof96jd9fXl52dTVFiIvv/wKQWWt2vtD7v15OSP9HtGpjc+BoALlJ391zKS4OBgL1eCyxqzzQavTTdv2LBBdevW1bRp0xQcHKzWrVurdevWCg4O1rRp01S/fn1t3LjxvOM4HA5lZWW5Hc78vBL4BCgJNptNE4ffoe++36n/7NwvSYqoFCTHyVwdzT7udu2Bw1kKrxQkSap5ZWX5+dk08oEOGjHpQ/UZ8YYqBpfTkplDVKZ0qRL/HAAuTH5+viaNH6emzZqrzlV1vV0OYCleSxKHDh2qO++8U7NmzTIWizqdTj388MMaOnSoUlJSzjlOUlKSxo4d63auVPi1KhN5XbHXjJI3NeEuXV0nUu36TynS+2w2m/zLlNYTEz7Q8rU/S5LiEuZoz9JxanNtXdYmApeIpOcSlZa2Q7PfWujtUnCZ48EVk9eSxB9++EHDhg0r8L8Um82mYcOGKTU19bzjJCQk6OjRo25H6fAWHqgYJW3KqDvV5aZG6jhwmv57INN1Pv1wluz+ZRRcoazb9WGVgpRxOOuvaw799b9/3pXuev3QH9k6lJmtqhEVPV88gIs2/vlEfbNqpV5/8y2FR0R4uxzAcrzWJEZERGj9+vVnfX39+vUKDw8/7zh2u11BQUFuh82P6cRL3ZRRd+q2m5uo06Bp+nXfYbfXvv9pr07mnlJsdD3Xuauqh6laZKjWbdktSUpJ3fXX+RphrmsqBpVT5ZAK2rv/SAl8AgAXyul0avzziUpevkyvvjlHV1x5pbdLggXYbDaPHZcqr003Dx8+XA899JA2bdqkdu3auRrCjIwMLV++XK+//romTZrkrfLgRVMT7tLdnVvqzmGvKTvnhMIrBUqSjmaf0AlHrrKyT2jO4hS98ERPHTmaoz9zTmjyqDu19oddWv/jHklS2t4D+nTFD5o04g4Nee5tZWWfUOLQ27R9T4ZWbeRpZ8CXJT2XqC8+X6Ip02aofPnyOnTooCSpQoVABQQEeLk6wDq8ugXOu+++qylTpmjTpk3Ky/vrYZNSpUqpRYsWio+P11133XVB47IFzqXt+PcvF3h+4DPzNP/TdZL+t5n2XZ3+fzPt737SY0nvKuPw/zbTDiwfoAnDe6r7zU2Vn+/Umk07NHziBzzdfIljC5zLX7NG9Qs8P/a5cbqtR88SrgYlyZtb4NQZ/oXHxk6b1NljY3uST+yTmJubq0OHDkmSKleurDJlylzUeDSJwOWLJhG4fNEk+haf+MWVMmXKKDIyUpGRkRfdIAIAABSVL61JXL16tbp166aoqCjZbDYtXrzY7fV+/foZ9+jUqZPbNUeOHNG9996roKAghYSEaMCAAcrOzi5SHT7RJAIAAHiTzea5o6hycnLUpEkTzZgx46zXdOrUSfv373cdb7/9ttvr9957r7Zt26alS5dqyZIlWr16tR566KEi1eHVX1wBAACAu86dO6tz53NPUdvtdkWcZWuon376SV9++aU2bNigli1bSpKmT5+uLl26aNKkSYqKiipUHSSJAADA8jw53VzQr8M5HI6LqnflypUKCwtTvXr19Mgjj+jw4f9tF5eSkqKQkBBXgyhJ7du3l5+fn9atW1foe9AkAgAAeFBSUpKCg4PdjqSkpAser1OnTnrrrbe0fPlyvfDCC1q1apU6d+7s2ikmPT1dYWFhbu8pXbq0QkNDlZ6eXtCQBWK6GQAAWJ4n97xOSEhQfHy82zm73X7B4/Xu3dv1nxs3bqxrrrlGtWvX1sqVK9WuXbsLHvdMJIkAAAAeVNCvw11Mk3imWrVqqXLlykpLS5P016/aHThwwO2aU6dO6ciRI2ddx1gQmkQAAGB5fn42jx2e9vvvv+vw4cOKjIyUJMXExCgzM1ObNm1yXZOcnKz8/HxFR0cXelymmwEAAHxIdna2KxWUpN27dys1NVWhoaEKDQ3V2LFj1atXL0VERGjnzp0aOXKk6tSpo44dO0qSGjRooE6dOmngwIGaNWuWcnNzNWTIEPXu3bvQTzZLJIkAAAA+tU/ixo0b1axZMzVr1kySFB8fr2bNmumZZ55RqVKltGXLFt12222qW7euBgwYoBYtWuibb75xm8JesGCB6tevr3bt2qlLly668cYb9dprrxWpDpJEAABgeRfyyyie0rZtW53rV5O/+uqr844RGhqqhQsXXlQdJIkAAAAwkCQCAADL86Eg0WeQJAIAAMBAkggAACzPl9Yk+gqSRAAAABhIEgEAgOWRJJpIEgEAAGAgSQQAAJZHkGiiSQQAAJbHdLOJ6WYAAAAYSBIBAIDlESSaSBIBAABgIEkEAACWx5pEE0kiAAAADCSJAADA8ggSTSSJAAAAMJAkAgAAy2NNookkEQAAAAaSRAAAYHkEiSaaRAAAYHlMN5uYbgYAAICBJBEAAFgeQaKJJBEAAAAGkkQAAGB5rEk0kSQCAADAQJIIAAAsjyDRRJIIAAAAA0kiAACwPNYkmmgSAQCA5dEjmphuBgAAgIEkEQAAWB7TzSaSRAAAABhIEgEAgOWRJJpIEgEAAGAgSQQAAJZHkGgiSQQAAICBJBEAAFgeaxJNNIkAAMDy6BFNTDcDAADAQJIIAAAsj+lmE0kiAAAADCSJAADA8ggSTSSJAAAAMJAkAgAAy/MjSjSQJAIAAMBAkwgAACzPZvPcUVSrV69Wt27dFBUVJZvNpsWLF7tey83N1ahRo9S4cWOVL19eUVFRuv/++7Vv3z63MWrUqCGbzeZ2jB8/vkh10CQCAADLO7OhKs6jqHJyctSkSRPNmDHDeO3YsWPavHmznn76aW3evFkfffSRtm/frttuu824NjExUfv373cdQ4cOLVIdrEkEAADwIZ07d1bnzp0LfC04OFhLly51O/fyyy/ruuuu0969e1WtWjXX+cDAQEVERFxwHSSJAADA8vxsnjscDoeysrLcDofDUWy1Hz16VDabTSEhIW7nx48fr0qVKqlZs2aaOHGiTp06VbTvpNgqBAAAgCEpKUnBwcFuR1JSUrGMfeLECY0aNUr33HOPgoKCXOcfffRRvfPOO1qxYoUGDRqkcePGaeTIkUUam+lmAABgeZ78Wb6EhATFx8e7nbPb7Rc9bm5uru666y45nU7NnDnT7bW/3++aa66Rv7+/Bg0apKSkpELfmyYRAADAg+x2e7E0hX93ukH89ddflZyc7JYiFiQ6OlqnTp3Snj17VK9evULdgyYRAABY3qW0l/bpBnHHjh1asWKFKlWqdN73pKamys/PT2FhYYW+D00iAACAD8nOzlZaWprr7927dys1NVWhoaGKjIzUHXfcoc2bN2vJkiXKy8tTenq6JCk0NFT+/v5KSUnRunXrFBsbq8DAQKWkpGjYsGHq27evKlasWOg6aBIBAIDl2eQ7UeLGjRsVGxvr+vv0+sK4uDiNGTNGn3zyiSSpadOmbu9bsWKF2rZtK7vdrnfeeUdjxoyRw+FQzZo1NWzYMGNd5PnQJAIAAMvz850eUW3btpXT6Tzr6+d6TZKaN2+utWvXXnQdbIEDAAAAA0kiAACwPE9ugXOpIkkEAACAgSQRAABYHkGiiSQRAAAABpJEAABgeX5EiQaSRAAAABhIEgEAgOURJJpoEgEAgOWxBY6J6WYAAAAYSBIBAIDlESSaSBIBAABgIEkEAACWxxY4JpJEAAAAGEgSAQCA5ZEjmkgSAQAAYCBJBAAAlsc+iSaaRAAAYHl+9IgGppsBAABgIEkEAACWx3SziSQRAAAABpJEAABgeQSJJpJEAAAAGEgSAQCA5bEm0USSCAAAAANJIgAAsDz2STTRJAIAAMtjutnEdDMAAAAMJIkAAMDyyBFNJIkAAAAwXFCT+M0336hv376KiYnRf//7X0nSvHnztGbNmmItDgAAoCT42WweOy5VRW4SP/zwQ3Xs2FFly5bV999/L4fDIUk6evSoxo0bV+wFAgAAoOQVuUl87rnnNGvWLL3++usqU6aM63yrVq20efPmYi0OAACgJNhsnjsuVUVuErdv367WrVsb54ODg5WZmVkcNQEAAMDLitwkRkREKC0tzTi/Zs0a1apVq1iKAgAAKEk2m81jx6WqyE3iwIED9dhjj2ndunWy2Wzat2+fFixYoOHDh+uRRx7xRI0AAAAoYUXeJ/HJJ59Ufn6+2rVrp2PHjql169ay2+0aPny4hg4d6okaAQAAPOoSDvw8pshNos1m07/+9S+NGDFCaWlpys7OVsOGDVWhQgVP1AcAAOBxl/JWNZ5ywb+44u/vr4YNGxZnLQAAAPARRW4SY2Njz7kIMzk5+aIKAgAAKGkEiaYiN4lNmzZ1+zs3N1epqanaunWr4uLiiqsuAAAAeFGRm8QpU6YUeH7MmDHKzs6+6IIAAABK2qW8VY2nXNBvNxekb9++evPNN4trOAAAAHjRBT+4cqaUlBQFBAQU13AX5Y8NL3u7BAAeUjEm3tslAPCQ4xsme+3exZaaXUaK3CT27NnT7W+n06n9+/dr48aNevrpp4utMAAAAHhPkZvE4OBgt7/9/PxUr149JSYmqkOHDsVWGAAAQElhTaKpSE1iXl6e+vfvr8aNG6tixYqeqgkAAKBE+flQj7h69WpNnDhRmzZt0v79+7Vo0SL16NHD9brT6dTo0aP1+uuvKzMzU61atdLMmTN11VVXua45cuSIhg4dqk8//VR+fn7q1auXXnrppSL9+EmRpuBLlSqlDh06KDMzsyhvAwAAQCHl5OSoSZMmmjFjRoGvT5gwQdOmTdOsWbO0bt06lS9fXh07dtSJEydc19x7773atm2bli5dqiVLlmj16tV66KGHilRHkaebGzVqpF27dqlmzZpFfSsAAIBP8mSS6HA45HA43M7Z7XbZ7fYCr+/cubM6d+5c4GtOp1NTp07VU089pe7du0uS3nrrLYWHh2vx4sXq3bu3fvrpJ3355ZfasGGDWrZsKUmaPn26unTpokmTJikqKqpQdRf5YZ7nnntOw4cP15IlS7R//35lZWW5HQAAAPifpKQkBQcHux1JSUkXNNbu3buVnp6u9u3bu84FBwcrOjpaKSkpkv7acSYkJMTVIEpS+/bt5efnp3Xr1hX6XoVOEhMTE/XEE0+oS5cukqTbbrvNbZGn0+mUzWZTXl5eoW8OAADgCzz54EpCQoLi49237zpbing+6enpkqTw8HC38+Hh4a7X0tPTFRYW5vZ66dKlFRoa6rqmMArdJI4dO1YPP/ywVqxYUejBAQAArO5cU8u+rNBNotPplCS1adPGY8UAAAB4gy893XwuERERkqSMjAxFRka6zmdkZKhp06auaw4cOOD2vlOnTunIkSOu9xdGkdYksocQAACA99SsWVMRERFavny561xWVpbWrVunmJgYSVJMTIwyMzO1adMm1zXJycnKz89XdHR0oe9VpKeb69ate95G8ciRI0UZEgAAwOt8KQfLzs5WWlqa6+/du3crNTVVoaGhqlatmh5//HE999xzuuqqq1SzZk09/fTTioqKcu2l2KBBA3Xq1EkDBw7UrFmzlJubqyFDhqh3796FfrJZKmKTOHbsWOMXVwAAAC51fj7UJW7cuFGxsbGuv08/9BIXF6c5c+Zo5MiRysnJ0UMPPaTMzEzdeOON+vLLLxUQEOB6z4IFCzRkyBC1a9fOtZn2tGnTilSHzXl6seF5+Pn5Ffi0jC86ccrbFQDwlIox8ee/CMAl6fiGyV6795Of/+Kxscd3qeuxsT2p0Eki6xEBAMDlqsgbR1tAob+TQgaOAAAAuAwUOknMz8/3ZB0AAABew4SpiXQVAAAAhiI93QwAAHA58qWnm30FSSIAAAAMJIkAAMDyCBJNNIkAAMDyLpXfbi5JTDcDAADAQJIIAAAsjwdXTCSJAAAAMJAkAgAAyyNINJEkAgAAwECSCAAALI+nm00kiQAAADCQJAIAAMuziSjxTDSJAADA8phuNjHdDAAAAANJIgAAsDySRBNJIgAAAAwkiQAAwPJs7KZtIEkEAACAgSQRAABYHmsSTSSJAAAAMJAkAgAAy2NJookmEQAAWJ4fXaKB6WYAAAAYSBIBAIDl8eCKiSQRAAAABpJEAABgeSxJNJEkAgAAwECSCAAALM9PRIlnIkkEAACAgSQRAABYHmsSTTSJAADA8tgCx8R0MwAAAAwkiQAAwPL4WT4TSSIAAAAMJIkAAMDyCBJNJIkAAAAwkCQCAADLY02iiSQRAAAABpJEAABgeQSJJppEAABgeUytmvhOAAAAYKBJBAAAlmez2Tx2FEWNGjUKHGPw4MGSpLZt2xqvPfzww574SphuBgAA8BUbNmxQXl6e6++tW7fqlltu0Z133uk6N3DgQCUmJrr+LleunEdqoUkEAACW5yvPrVSpUsXt7/Hjx6t27dpq06aN61y5cuUUERHh8VqYbgYAAPAgh8OhrKwst8PhcJz3fSdPntT8+fP1wAMPuE1bL1iwQJUrV1ajRo2UkJCgY8eOeaRumkQAAGB5fjabx46kpCQFBwe7HUlJSeetafHixcrMzFS/fv1c5/r06aP58+drxYoVSkhI0Lx589S3b1+PfCc2p9Pp9MjIXnTilLcrAOApFWPivV0CAA85vmGy1+49f9PvHhv7zkZVjOTQbrfLbref830dO3aUv7+/Pv3007Nek5ycrHbt2iktLU21a9culnpPY00iAACwPE+uSSxMQ3imX3/9VcuWLdNHH310zuuio6MliSYRAADAE3ztF1dmz56tsLAwde3a9ZzXpaamSpIiIyOLvQaaRAAAAB+Sn5+v2bNnKy4uTqVL/69V27lzpxYuXKguXbqoUqVK2rJli4YNG6bWrVvrmmuuKfY6aBIBAIDlFXXTa09atmyZ9u7dqwceeMDtvL+/v5YtW6apU6cqJydHVatWVa9evfTUU095pA6aRAAAAB/SoUMHFfRccdWqVbVq1aoSq4MmEQAAWB57Apr4TgAAAGAgSQQAAJbnS2sSfQVJIgAAAAwkiQAAwPLIEU0kiQAAADCQJAIAAMtjTaKJJhEAAFgeU6smvhMAAAAYSBIBAIDlMd1sIkkEAACAgSQRAABYHjmiiSQRAAAABpJEAABgeSxJNJEkAgAAwECSCAAALM+PVYkGmkQAAGB5TDebmG4GAACAgSQRAABYno3pZgNJIgAAAAwkiQAAwPJYk2giSQQAAICBJBEAAFgeW+CYSBIBAABgIEkEAACWx5pEE00iAACwPJpEE9PNAAAAMJAkAgAAy2MzbRNJIgAAAAwkiQAAwPL8CBINJIkAAAAwkCQCAADLY02iiSQRAAAABpJEAABgeeyTaKJJBAAAlsd0s4npZgAAABhIEgEAgOWxBY6JJBEAAAAGkkQAAGB5rEk0kSQCAADAQJKIS9o7Cxdo7uw3dOjQQdWtV19P/vNpNb7mGm+XBeAshvdrpx6xjVW3epiOO3K1bsse/evlJdrx60HXNXb/0hr/+G2685ZmsvuX1rK12/XYCx/owJFsSVLjq6I0PO5m3dC0pioFV9Cv+4/o3x99pxnvfOOtj4XLAFvgmEgSccn68ovPNWlCkgb9Y7DeeX+R6tWrr0cGDdDhw4e9XRqAs7ipeW3Nev9btXngJd065FWVLl1KS6YPUrkAf9c1E4Z1V9ebrta9CXPVYdAMRVYO0jsT+rteb1b/Sh38I1v9n1mo5r1f0AuzlylxcFc9fOeN3vhIwGXL5nQ6nd4uoridOOXtClAS7u19p65u1Fj/fOoZSVJ+fr46tGuje/rcpwEDH/JydfCUijHx3i4BxahySHn9tvRZtX/oZX37/S4FlQ/Qb0sT1e+p+VqUvEWSVLd6mH744Em16f+S1m/9tcBxpozsqfo1wtX5HzNLsnwUs+MbJnvt3t/u+MNjY7e6qqLHxvYkkkRcknJPntRP/9mm62NucJ3z8/PT9dffoC0/fO/FygAURVCFspKkP7KOSZKaNbhS/mVKK3n9L65rfvn1gPbuP6LoxtXPOk5whbKuMYAL4Wezeey4VPl0k/jbb7/pgQceOOc1DodDWVlZbofD4SihCuEtf2T+oby8PFWqVMntfKVKlXTo0CEvVQWgKGw2mybGd9d3qbv0n53pkqSISkFynDylo9kn3K49cCRb4ZWCChzn+mtq6I5bmuqNRSkerxmwEp9uEo8cOaK5c+ee85qkpCQFBwe7HRNfSCqhCgEAF2rqyJ66unak7v/XvAseo2HtCL036QE9//pXWr7ul/O/ATgLmwePohgzZoxsNpvbUb9+fdfrJ06c0ODBg1WpUiVVqFBBvXr1UkZGxoV+7HPy6tPNn3zyyTlf37Vr13nHSEhIUHy8+xolZyn7RdUF31cxpKJKlSplPKRy+PBhVa5c2UtVASisKSN6qstNDdX+oRn674GjrvPph7Nk9y+t4AoBbmliWGgFZRzOchujfs1wfT7jEb25KEUvvLmsxGoHPO3qq6/WsmX/+7/p0qX/164NGzZMn332md5//30FBwdryJAh6tmzp7799ttir8OrTWKPHj1ks9l0rmdnbOeZy7fb7bLb3ZtCHly5/JXx91eDhldr3doU3dyuvaS/HlxZty5Fve/p6+XqAJzLlBE9dVvbxurw8Az9uu+I22vf//S7TuaeUuy1dbV4xV8PrlxVvYqqRYZq3Y//e2ilQa1wffHKP7Tgsw0aM/OLEq0flykfWjpYunRpRUREGOePHj2qN954QwsXLtTNN98sSZo9e7YaNGigtWvX6vrrry/WOrw63RwZGamPPvpI+fn5BR6bN2/2ZnnwcffF9ddHH7ynTxYv0q6dO/Vc4hgdP35cPW7v6e3SAJzF1FG91LtzC8U9PV/ZxxwKrxSo8EqBCrCXkSRl5ZzQnI/X6YVht6l1izpqVv9KvfZMb63dstv1ZHPD2hH6cuY/tHzddk1buMo1RuWQ8t78aMBZFfX5iR07digqKkq1atXSvffeq71790qSNm3apNzcXLVv3951bf369VWtWjWlpBT/mlyvJoktWrTQpk2b1L179wJfP1/KCGvr1LmL/jhyRK+8PE2HDh1UvfoN9Mqr/1YlppsBnzXojlaSpKWvDnY7P3Ds25q/ZIMkaeSUj5XvdOrtF/rJ7l/q/zfT/tB17e03N1FYaKD6dGmpPl1aus7/uu+I6nd/rgQ+BS5HnvxZvqSkJI0dO9bt3OjRozVmzBjj2ujoaM2ZM0f16tXT/v37NXbsWN10003aunWr0tPT5e/vr5CQELf3hIeHKz09vdjr9uo+id98841ycnLUqVOnAl/PycnRxo0b1aZNmyKNy3QzcPlin0Tg8uXNfRLX7Tx6/osuUNMrA4zksKDlcgXJzMxU9erVNXnyZJUtW1b9+/c3xrruuusUGxurF154oVjr9mqSeNNNN53z9fLlyxe5QQQAACgqT25nWNiGsCAhISGqW7eu0tLSdMstt+jkyZPKzMx0SxMzMjIKXMN4sXx6CxwAAICS4Ctb4JwpOztbO3fuVGRkpFq0aKEyZcpo+fLlrte3b9+uvXv3KiYm5iLvZPJqkggAAID/GT58uLp166bq1atr3759Gj16tEqVKqV77rlHwcHBGjBggOLj4xUaGqqgoCANHTpUMTExxf5ks0STCAAA4DNb4Pz++++65557dPjwYVWpUkU33nij1q5dqypVqkiSpkyZIj8/P/Xq1UsOh0MdO3bUK6+84pFavPrgiqfw4Apw+eLBFeDy5c0HVzbs9tyDK9fWDPbY2J5EkggAACzPk1vgXKp4cAUAAAAGkkQAAGB5ntwC51JFkggAAAADSSIAALA8gkQTTSIAAABdooHpZgAAABhIEgEAgOWxBY6JJBEAAAAGkkQAAGB5bIFjIkkEAACAgSQRAABYHkGiiSQRAAAABpJEAAAAokQDTSIAALA8tsAxMd0MAAAAA0kiAACwPLbAMZEkAgAAwECSCAAALI8g0USSCAAAAANJIgAAAFGigSQRAAAABpJEAABgeeyTaCJJBAAAgIEkEQAAWB77JJpoEgEAgOXRI5qYbgYAAICBJBEAAIAo0UCSCAAAAANJIgAAsDy2wDGRJAIAAMBAkggAACyPLXBMJIkAAAAwkCQCAADLI0g00SQCAADQJRqYbgYAAICBJBEAAFgeW+CYSBIBAABgIEkEAACWxxY4JpJEAAAAGEgSAQCA5REkmkgSAQAAYCBJBAAAIEo00CQCAADLYwscE9PNAAAAMNAkAgAAy7PZPHcURVJSkq699loFBgYqLCxMPXr00Pbt292uadu2rWw2m9vx8MMPF+O38ReaRAAAAB+xatUqDR48WGvXrtXSpUuVm5urDh06KCcnx+26gQMHav/+/a5jwoQJxV4LaxIBAIDl+cqKxC+//NLt7zlz5igsLEybNm1S69atXefLlSuniIgIj9ZCkggAAOBBDodDWVlZbofD4SjUe48ePSpJCg0NdTu/YMECVa5cWY0aNVJCQoKOHTtW7HXTJAIAANg8dyQlJSk4ONjtSEpKOm9J+fn5evzxx9WqVSs1atTIdb5Pnz6aP3++VqxYoYSEBM2bN099+/Ytnu/hb2xOp9NZ7KN62YlT3q4AgKdUjIn3dgkAPOT4hsleu/eewyc8NnZkBZuRHNrtdtnt9nO+75FHHtEXX3yhNWvW6MorrzzrdcnJyWrXrp3S0tJUu3btYqlZYk0iAACAR/dJLExDeKYhQ4ZoyZIlWr169TkbREmKjo6WJJpEAACA4lbUrWo8xel0aujQoVq0aJFWrlypmjVrnvc9qampkqTIyMhirYUmEQAAwEcMHjxYCxcu1Mcff6zAwEClp6dLkoKDg1W2bFnt3LlTCxcuVJcuXVSpUiVt2bJFw4YNU+vWrXXNNdcUay2sSQRwSWFNInD58uaaxN+OFO5p4wtRNbTwU822s0Sas2fPVr9+/fTbb7+pb9++2rp1q3JyclS1alXdfvvteuqppxQUFFRcJUsiSQQAAPAZ58vuqlatqlWrVpVILTSJAADA8nxlTaIvYZ9EAAAAGEgSAQAAfOaH+XwHSSIAAAAMJIkAAMDyWJNookkEAACWR49oYroZAAAABpJEAABgeUw3m0gSAQAAYCBJBAAAlmdjVaKBJBEAAAAGkkQAAACCRANJIgAAAAwkiQAAwPIIEk00iQAAwPLYAsfEdDMAAAAMJIkAAMDy2ALHRJIIAAAAA0kiAAAAQaKBJBEAAAAGkkQAAGB5BIkmkkQAAAAYSBIBAIDlsU+iiSYRAABYHlvgmJhuBgAAgIEkEQAAWB7TzSaSRAAAABhoEgEAAGCgSQQAAICBNYkAAMDyWJNoIkkEAACAgSQRAABYHvskmmgSAQCA5THdbGK6GQAAAAaSRAAAYHkEiSaSRAAAABhIEgEAAIgSDSSJAAAAMJAkAgAAy2MLHBNJIgAAAAwkiQAAwPLYJ9FEkggAAAADSSIAALA8gkQTTSIAAABdooHpZgAAABhoEgEAgOXZPPg/F2LGjBmqUaOGAgICFB0drfXr1xfzJz4/mkQAAAAf8u677yo+Pl6jR4/W5s2b1aRJE3Xs2FEHDhwo0TpoEgEAgOXZbJ47imry5MkaOHCg+vfvr4YNG2rWrFkqV66c3nzzzeL/4OdAkwgAAOBBDodDWVlZbofD4Sjw2pMnT2rTpk1q376965yfn5/at2+vlJSUkipZ0mX6dHPAZfmpUBCHw6GkpCQlJCTIbrd7uxyUgOMbJnu7BJQQ/vlGSfJk7zDmuSSNHTvW7dzo0aM1ZswY49pDhw4pLy9P4eHhbufDw8P1888/e67IAticTqezRO8IFKOsrCwFBwfr6NGjCgoK8nY5AIoR/3zjcuFwOIzk0G63F/j//Ozbt09XXHGFvvvuO8XExLjOjxw5UqtWrdK6des8Xu9pZG4AAAAedLaGsCCVK1dWqVKllJGR4XY+IyNDERERnijvrFiTCAAA4CP8/f3VokULLV++3HUuPz9fy5cvd0sWSwJJIgAAgA+Jj49XXFycWrZsqeuuu05Tp05VTk6O+vfvX6J10CTikma32zV69GgWtQOXIf75hlXdfffdOnjwoJ555hmlp6eradOm+vLLL42HWTyNB1cAAABgYE0iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIi5pM2bMUI0aNRQQEKDo6GitX7/e2yUBuEirV69Wt27dFBUVJZvNpsWLF3u7JMCSaBJxyXr33XcVHx+v0aNHa/PmzWrSpIk6duyoAwcOeLs0ABchJydHTZo00YwZM7xdCmBpbIGDS1Z0dLSuvfZavfzyy5L+2pG+atWqGjp0qJ588kkvVwegONhsNi1atEg9evTwdimA5ZAk4pJ08uRJbdq0Se3bt3ed8/PzU/v27ZWSkuLFygAAuDzQJOKSdOjQIeXl5Rm7z4eHhys9Pd1LVQEAcPmgSQQAAICBJhGXpMqVK6tUqVLKyMhwO5+RkaGIiAgvVQUAwOWDJhGXJH9/f7Vo0ULLly93ncvPz9fy5csVExPjxcoAALg8lPZ2AcCFio+PV1xcnFq2bKnrrrtOU6dOVU5Ojvr37+/t0gBchOzsbKWlpbn+3r17t1JTUxUaGqpq1ap5sTLAWtgCB5e0l19+WRMnTlR6erqaNm2qadOmKTo62ttlAbgIK1euVGxsrHE+Li5Oc+bMKfmCAIuiSQQAAICBNYkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIgAAAAw0iQB8Vr9+/dSjRw/X323bttXjjz9e4nWsXLlSNptNmZmZJX5vAPAWmkQARdavXz/ZbDbZbDb5+/urTp06SkxM1KlTpzx6348++kjPPvtsoa6lsQOAi1Pa2wUAuDR16tRJs2fPlsPh0Oeff67BgwerTJkySkhIcLvu5MmT8vf3L5Z7hoaGFss4AIDzI0kEcEHsdrsiIiJUvXp1PfLII2rfvr0++eQT1xTx888/r6ioKNWrV0+S9Ntvv+muu+5SSEiIQkND1b17d+3Zs8c1Xl5enuLj4xUSEqJKlSpp5MiROvOn5c+cbnY4HBo1apSqVq0qu92uOnXq6I033tCePXsUGxsrSapYsaJsNpv69esnScrPz1dSUpJq1qypsmXLqkmTJvrggw/c7vP555+rbt26Klu2rGJjY93qBACroEkEUCzKli2rkydPSpKWL1+u7du3a+nSpVqyZIlyc3PVsWNHBQYG6ptvvtG3336rChUqqFOnTq73vPjii5ozZ47efPNNrVmzRkeOHNGiRYvOec/7779fb7/9tqZNm6affvpJr776qipUqKCqVavqww8/lCRt375d+/fv10svvSRJSkpK0ltvvaVZs2Zp27ZtGjZsmPr27atVq1ZJ+quZ7dmzp7p166bU1FQ9+OCDevLJJz31tQGAz2K6GcBFcTqdWr58ub766isNHTpUBw8eVPny5fXvf//bNc08f/585efn69///rdsNpskafbs2QoJCdHKlSvVoUMHTZ06VQkJCerZs6ckadasWfrqq6/Oet9ffvlF7733npYuXar27dtLkmrVquV6/fTUdFhYmEJCQiT9lTyOGzdOy5YtU0xMjOs9a9as0auvvqo2bdpo5syZql27tl588UVJUr169fTjjz/qhRdeKMZvDQB8H00igAuyZMkSVahQQbm5ucrPz1efPn00ZswYDR48WI0bN3Zbh/jDDz8oLS1NgYGBbmOcOHFCO3fu1NGjR7V//35FR0e7XitdurRatmxpTDmflpqaqlKlSqlNmzaFrjktLU3Hjh3TLbfc4nb+5MmTatasmSTpp59+cqtDkquhBAAroUkEcEFiY2M1c+ZM+fv7KyoqSqVL/+9fJ+XLl3e7Njs7Wy1atNCCBQuMcapUqXJB9y9btmyR35OdnS1J+uyzz3TFFVe4vWa32y+oDgC4XNEkArgg5cuXV506dQp1bfPmzfXuu+8qLCxMQUFBBV4TGRmpdevWqXXr1pKkU6dOadOmTWrevHmB1zdu3Fj5+flatWqVa7r5704nmXl5ea5zDRs2lN1u1969e8+aQDZo0ECffPKJ27m1a9ee/0MCwGWGB1cAeNy9996rypUrq3v37vrmm2+0e/durVy5Uo8++qh+//13SdJjjz2m8ePHa/Hixfr555/1j3/845x7HNaoUUNxcXF64IEHtHjxYteY7733niSpevXqstlsWrJkiQ4ePKjs7GwFBgZq+PDhGjZsmObOnaudO3dq8+bNmj59uubOnStJevjhh7Vjxw6NGDFC27dv18KFCzVnzhxPf0UA4HNoEgF4XLly5bR69WpVq1ZNPXv2VIMGDTRgwACdOHHClSw+8cQTuu+++xQXF6eYmBgFBgbq9ttvP+e4M2fO1B133KF//OMfql+/vgYOHKicnBxJ0hVXXKGxY8fqySefVHh4uIYMGSJJevbZZ/X0008rKSlJDRo0UKdOnfTZZ5+pZs2akqRq1arpww8/1OLFi9WkSRPNmjVL48aN8+C3AwC+yeY826pwAAAAWBZJIgAAAAw0iQAAADDQJAIAAMBAkwgAAAADTSIAAAAMNIkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwPB/RX1bRB85OKMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WEVqbLdcy8gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use this model (NEW)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, Attention, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=25)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define CNN-BiLSTM with attention model\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "conv_layer1 = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)\n",
        "conv_layer2 = Conv1D(filters=64, kernel_size=3, activation='relu')(conv_layer1)\n",
        "conv_layer3 = Conv1D(filters=64, kernel_size=3, activation='relu')(conv_layer2)\n",
        "bi_lstm_layer1 = Bidirectional(LSTM(64, return_sequences=True))(conv_layer3)\n",
        "bi_lstm_layer2 = Bidirectional(LSTM(64, return_sequences=True))(bi_lstm_layer1)\n",
        "attention_layer = Attention()([bi_lstm_layer2, bi_lstm_layer2])\n",
        "flatten_layer = Flatten()(attention_layer)\n",
        "output_layer = Dense(y_train.shape[1], activation='softmax')(flatten_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape data for Conv1D\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_cnn, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_cnn)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "class_report = classification_report(y_true_classes, y_pred_classes)\n",
        "\n",
        "print(\"Accuracy score\",accuracy_score(y_true_classes, y_pred_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wWD1FrJfMrd",
        "outputId": "499893b4-8d36-4dfb-93b5-4f80ab564e18"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 14s 107ms/step - loss: 0.6012 - accuracy: 0.6458 - val_loss: 0.5817 - val_accuracy: 0.6646\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 0.3496 - accuracy: 0.8695 - val_loss: 0.2301 - val_accuracy: 0.9116\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 0.1977 - accuracy: 0.9183 - val_loss: 0.1816 - val_accuracy: 0.9177\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 4s 99ms/step - loss: 0.1562 - accuracy: 0.9374 - val_loss: 0.1384 - val_accuracy: 0.9390\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 0.1264 - accuracy: 0.9443 - val_loss: 0.1560 - val_accuracy: 0.9299\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 0.1207 - accuracy: 0.9542 - val_loss: 0.1111 - val_accuracy: 0.9451\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 0.0873 - accuracy: 0.9702 - val_loss: 0.0939 - val_accuracy: 0.9634\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 3s 76ms/step - loss: 0.0721 - accuracy: 0.9687 - val_loss: 0.1071 - val_accuracy: 0.9482\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 4s 94ms/step - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.0891 - val_accuracy: 0.9634\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 4s 95ms/step - loss: 0.0484 - accuracy: 0.9786 - val_loss: 0.0543 - val_accuracy: 0.9695\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0952 - val_accuracy: 0.9695\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 0.0640 - val_accuracy: 0.9787\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 4s 105ms/step - loss: 0.0661 - accuracy: 0.9740 - val_loss: 0.0713 - val_accuracy: 0.9604\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0483 - val_accuracy: 0.9787\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0430 - val_accuracy: 0.9848\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.0939 - val_accuracy: 0.9604\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 3s 77ms/step - loss: 0.0184 - accuracy: 0.9931 - val_loss: 0.0725 - val_accuracy: 0.9726\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 4s 93ms/step - loss: 0.0314 - accuracy: 0.9863 - val_loss: 0.0463 - val_accuracy: 0.9817\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 2s 59ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0904 - val_accuracy: 0.9787\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.1260 - val_accuracy: 0.9726\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 0.0072 - accuracy: 0.9962 - val_loss: 0.0778 - val_accuracy: 0.9817\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 3s 76ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0787 - val_accuracy: 0.9817\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 4s 88ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0500 - val_accuracy: 0.9817\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 0.0109 - accuracy: 0.9985 - val_loss: 0.0404 - val_accuracy: 0.9878\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0606 - val_accuracy: 0.9878\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.9881e-04 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9878\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 4s 87ms/step - loss: 1.0353e-04 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9878\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 3s 77ms/step - loss: 7.3138e-05 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9878\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 5.6094e-05 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9878\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 4.5589e-05 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9848\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 3.7683e-05 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9848\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 5s 114ms/step - loss: 3.2127e-05 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9848\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 2.7729e-05 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9848\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 2.4282e-05 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9848\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 2.1602e-05 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9848\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 3s 74ms/step - loss: 1.9243e-05 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9848\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 4s 97ms/step - loss: 1.7329e-05 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9848\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.5705e-05 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9848\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 1.4411e-05 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9848\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.3059e-05 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9848\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 3s 83ms/step - loss: 1.2050e-05 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9848\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 3s 82ms/step - loss: 1.1176e-05 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9848\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 1.0270e-05 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9848\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 9.5413e-06 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9848\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 8.8878e-06 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9848\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 4s 98ms/step - loss: 8.3063e-06 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9848\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 7.7937e-06 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9848\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 7.3021e-06 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9848\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 3s 61ms/step - loss: 6.8469e-06 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9848\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 6.4518e-06 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9848\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 4s 98ms/step - loss: 6.0817e-06 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9848\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 5.7482e-06 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9848\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 5.4493e-06 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9848\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 5.1456e-06 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9848\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 3s 75ms/step - loss: 4.8805e-06 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9848\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 4s 92ms/step - loss: 4.6395e-06 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9848\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 4.4102e-06 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9848\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 3s 61ms/step - loss: 4.1952e-06 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9848\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 4.0060e-06 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9848\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 3s 75ms/step - loss: 3.8138e-06 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9848\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 4s 91ms/step - loss: 3.6374e-06 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9848\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 2s 61ms/step - loss: 3.4782e-06 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9848\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 3s 67ms/step - loss: 3.3233e-06 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9848\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 3.1782e-06 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9848\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 4s 90ms/step - loss: 3.0459e-06 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9848\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 3s 83ms/step - loss: 2.9176e-06 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9848\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 2.8004e-06 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9848\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 2.6838e-06 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9848\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 2.5762e-06 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9848\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 4s 102ms/step - loss: 2.4745e-06 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9848\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 2.3776e-06 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9848\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 2.2854e-06 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9848\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 2.1962e-06 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9848\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 3s 61ms/step - loss: 2.1196e-06 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9848\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 4s 103ms/step - loss: 2.0389e-06 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9848\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 1.9626e-06 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9848\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 1.8911e-06 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9848\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.8231e-06 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9848\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 1.7589e-06 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9848\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 4s 92ms/step - loss: 1.6968e-06 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9848\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.6372e-06 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9848\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 3s 63ms/step - loss: 1.5824e-06 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9848\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 1.5273e-06 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9848\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 4s 88ms/step - loss: 1.4757e-06 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9848\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 3s 83ms/step - loss: 1.4289e-06 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9848\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 1.3803e-06 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9848\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 2s 60ms/step - loss: 1.3351e-06 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9848\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 1.2927e-06 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9848\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 4s 103ms/step - loss: 1.2499e-06 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9848\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.2091e-06 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9848\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 1.1715e-06 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9848\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 1.1350e-06 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9848\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 1.0984e-06 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9848\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 4s 101ms/step - loss: 1.0636e-06 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9848\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 3s 62ms/step - loss: 1.0320e-06 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9848\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 3s 66ms/step - loss: 9.9834e-07 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9848\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 3s 64ms/step - loss: 9.6986e-07 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9848\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 3s 78ms/step - loss: 9.3837e-07 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9848\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 4s 95ms/step - loss: 9.1116e-07 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9848\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 3s 65ms/step - loss: 8.8368e-07 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9848\n",
            "13/13 [==============================] - 2s 16ms/step\n",
            "Accuracy score 0.9829268292682927\n",
            "Confusion Matrix:\n",
            "[[201   7]\n",
            " [  0 202]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98       208\n",
            "           1       0.97      1.00      0.98       202\n",
            "\n",
            "    accuracy                           0.98       410\n",
            "   macro avg       0.98      0.98      0.98       410\n",
            "weighted avg       0.98      0.98      0.98       410\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPeBFGtDfaV5",
        "outputId": "f6c7985f-d94d-499f-bae5-6fc3688eab6b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)        [(None, 25, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)          (None, 23, 64)               256       ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)          (None, 21, 64)               12352     ['conv1d_20[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)          (None, 19, 64)               12352     ['conv1d_21[0][0]']           \n",
            "                                                                                                  \n",
            " bidirectional_14 (Bidirect  (None, 19, 128)              66048     ['conv1d_22[0][0]']           \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_15 (Bidirect  (None, 19, 128)              98816     ['bidirectional_14[0][0]']    \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " attention_7 (Attention)     (None, 19, 128)              0         ['bidirectional_15[0][0]',    \n",
            "                                                                     'bidirectional_15[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 2432)                 0         ['attention_7[0][0]']         \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 2)                    4866      ['flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 194690 (760.51 KB)\n",
            "Trainable params: 194690 (760.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performance comparison with other classifiers\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Flatten, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Alcoholism_eeg_dataset .csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.drop(columns=['Class']).values\n",
        "y = data['Class'].values\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, svm_pred))\n",
        "\n",
        "# KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, knn_pred))\n",
        "\n",
        "# Naive Bayes model\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "nb_pred = nb.predict(X_test)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_pred))\n",
        "print(\"Naive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, nb_pred))\n",
        "\n",
        "# Prepare data for neural networks\n",
        "X_train_nn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_nn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "y_train_nn = to_categorical(y_train)\n",
        "y_test_nn = to_categorical(y_test)\n",
        "\n",
        "# LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train_nn.shape[1], 1)),\n",
        "    Dense(y_train_nn.shape[1], activation='softmax')\n",
        "])\n",
        "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "lstm_model.fit(X_train_nn, y_train_nn, epochs=10, batch_size=32, verbose=0)\n",
        "lstm_pred = np.argmax(lstm_model.predict(X_test_nn), axis=1)\n",
        "print(\"LSTM Accuracy:\", accuracy_score(y_test, lstm_pred))\n",
        "print(\"LSTM Classification Report:\")\n",
        "print(classification_report(y_test, lstm_pred))\n",
        "\n",
        "# 1D CNN model\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_nn.shape[1], 1)),\n",
        "    Flatten(),\n",
        "    Dense(y_train_nn.shape[1], activation='softmax')\n",
        "])\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(X_train_nn, y_train_nn, epochs=10, batch_size=32, verbose=0)\n",
        "cnn_pred = np.argmax(cnn_model.predict(X_test_nn), axis=1)\n",
        "print(\"1D CNN Accuracy:\", accuracy_score(y_test, cnn_pred))\n",
        "print(\"1D CNN Classification Report:\")\n",
        "print(classification_report(y_test, cnn_pred))\n",
        "\n",
        "# BiLSTM model\n",
        "bilstm_model = Sequential([\n",
        "    Bidirectional(LSTM(64), input_shape=(X_train_nn.shape[1], 1)),\n",
        "    Dense(y_train_nn.shape[1], activation='softmax')\n",
        "])\n",
        "bilstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "bilstm_model.fit(X_train_nn, y_train_nn, epochs=10, batch_size=32, verbose=0)\n",
        "bilstm_pred = np.argmax(bilstm_model.predict(X_test_nn), axis=1)\n",
        "print(\"BiLSTM Accuracy:\", accuracy_score(y_test, bilstm_pred))\n",
        "print(\"BiLSTM Classification Report:\")\n",
        "print(classification_report(y_test, bilstm_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFCah-W2v7MJ",
        "outputId": "5c7d2ae8-1709-4be8-affe-296eb6d754d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9975609756097561\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       208\n",
            "           1       1.00      1.00      1.00       202\n",
            "\n",
            "    accuracy                           1.00       410\n",
            "   macro avg       1.00      1.00      1.00       410\n",
            "weighted avg       1.00      1.00      1.00       410\n",
            "\n",
            "KNN Accuracy: 0.9926829268292683\n",
            "KNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       208\n",
            "           1       0.99      1.00      0.99       202\n",
            "\n",
            "    accuracy                           0.99       410\n",
            "   macro avg       0.99      0.99      0.99       410\n",
            "weighted avg       0.99      0.99      0.99       410\n",
            "\n",
            "Naive Bayes Accuracy: 0.8536585365853658\n",
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       208\n",
            "           1       0.87      0.83      0.85       202\n",
            "\n",
            "    accuracy                           0.85       410\n",
            "   macro avg       0.85      0.85      0.85       410\n",
            "weighted avg       0.85      0.85      0.85       410\n",
            "\n",
            "13/13 [==============================] - 1s 12ms/step\n",
            "LSTM Accuracy: 0.8829268292682927\n",
            "LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.88       208\n",
            "           1       0.87      0.90      0.88       202\n",
            "\n",
            "    accuracy                           0.88       410\n",
            "   macro avg       0.88      0.88      0.88       410\n",
            "weighted avg       0.88      0.88      0.88       410\n",
            "\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "1D CNN Accuracy: 0.9975609756097561\n",
            "1D CNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       208\n",
            "           1       1.00      1.00      1.00       202\n",
            "\n",
            "    accuracy                           1.00       410\n",
            "   macro avg       1.00      1.00      1.00       410\n",
            "weighted avg       1.00      1.00      1.00       410\n",
            "\n",
            "13/13 [==============================] - 1s 14ms/step\n",
            "BiLSTM Accuracy: 0.8853658536585366\n",
            "BiLSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.88      0.89       208\n",
            "           1       0.87      0.90      0.89       202\n",
            "\n",
            "    accuracy                           0.89       410\n",
            "   macro avg       0.89      0.89      0.89       410\n",
            "weighted avg       0.89      0.89      0.89       410\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "vwdoHxLzWgTT",
        "outputId": "3d80baab-5ba2-44f3-9e18-df1d8bb73e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)        [(None, 25, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)          (None, 23, 64)               256       ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)          (None, 21, 64)               12352     ['conv1d_20[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)          (None, 19, 64)               12352     ['conv1d_21[0][0]']           \n",
            "                                                                                                  \n",
            " bidirectional_14 (Bidirect  (None, 19, 128)              66048     ['conv1d_22[0][0]']           \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_15 (Bidirect  (None, 19, 128)              98816     ['bidirectional_14[0][0]']    \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " attention_7 (Attention)     (None, 19, 128)              0         ['bidirectional_15[0][0]',    \n",
            "                                                                     'bidirectional_15[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 2432)                 0         ['attention_7[0][0]']         \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 2)                    4866      ['flatten_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 194690 (760.51 KB)\n",
            "Trainable params: 194690 (760.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# With PCA and without PCA comparison\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, Dense, Attention, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('Alcoholism_eeg_dataset .csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.drop(columns=['Class']).values\n",
        "y = data['Class'].values\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Function to build the model\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = Input(shape=(input_shape, 1))\n",
        "    conv_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)\n",
        "    bi_lstm_layer = Bidirectional(LSTM(64, return_sequences=True))(conv_layer)\n",
        "    attention_layer = Attention()([bi_lstm_layer, bi_lstm_layer])\n",
        "    flatten_layer = Flatten()(attention_layer)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(flatten_layer)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Assess performance with PCA\n",
        "pca = PCA(n_components=20)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y_categorical, test_size=0.2, random_state=42)\n",
        "X_train_pca_cnn = X_train_pca.reshape(X_train_pca.shape[0], X_train_pca.shape[1], 1)\n",
        "X_test_pca_cnn = X_test_pca.reshape(X_test_pca.shape[0], X_test_pca.shape[1], 1)\n",
        "\n",
        "model_pca = build_model(X_train_pca.shape[1], y_train.shape[1])\n",
        "model_pca.fit(X_train_pca_cnn, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "y_pred_pca = model_pca.predict(X_test_pca_cnn)\n",
        "y_pred_classes_pca = np.argmax(y_pred_pca, axis=1)\n",
        "y_true_classes_pca = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"With PCA:\")\n",
        "print(\"Accuracy score\",accuracy_score(y_true_classes, y_pred_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true_classes_pca, y_pred_classes_pca))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes_pca, y_pred_classes_pca))\n",
        "\n",
        "# Assess performance without PCA\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.2, random_state=42)\n",
        "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "model_no_pca = build_model(X_train.shape[1], y_train.shape[1])\n",
        "model_no_pca.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "y_pred_no_pca = model_no_pca.predict(X_test_cnn)\n",
        "y_pred_classes_no_pca = np.argmax(y_pred_no_pca, axis=1)\n",
        "y_true_classes_no_pca = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\nWithout PCA:\")\n",
        "print(\"Accuracy score\",accuracy_score(y_true_classes, y_pred_classes))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true_classes_no_pca, y_pred_classes_no_pca))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes_no_pca, y_pred_classes_no_pca))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ3CRSA9y9-I",
        "outputId": "3895e793-a210-4feb-9372-658e4087ab4a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 8s 55ms/step - loss: 0.5884 - accuracy: 0.6802 - val_loss: 0.4401 - val_accuracy: 0.8140\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.4383 - accuracy: 0.8038 - val_loss: 0.4169 - val_accuracy: 0.8049\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.3625 - accuracy: 0.8435 - val_loss: 0.3033 - val_accuracy: 0.8720\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.3049 - accuracy: 0.8641 - val_loss: 0.2745 - val_accuracy: 0.8872\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.2807 - accuracy: 0.8794 - val_loss: 0.2522 - val_accuracy: 0.8872\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.2672 - accuracy: 0.8901 - val_loss: 0.2241 - val_accuracy: 0.9207\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.2500 - accuracy: 0.8885 - val_loss: 0.2551 - val_accuracy: 0.8933\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 1s 33ms/step - loss: 0.2398 - accuracy: 0.8977 - val_loss: 0.2352 - val_accuracy: 0.8933\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 2s 47ms/step - loss: 0.2158 - accuracy: 0.9099 - val_loss: 0.1967 - val_accuracy: 0.9299\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 2s 44ms/step - loss: 0.2079 - accuracy: 0.9084 - val_loss: 0.1804 - val_accuracy: 0.9268\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.1781 - accuracy: 0.9206 - val_loss: 0.1749 - val_accuracy: 0.9238\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.1588 - accuracy: 0.9374 - val_loss: 0.1599 - val_accuracy: 0.9360\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.1663 - accuracy: 0.9305 - val_loss: 0.1293 - val_accuracy: 0.9482\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.1169 - accuracy: 0.9550 - val_loss: 0.1018 - val_accuracy: 0.9634\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0909 - accuracy: 0.9672 - val_loss: 0.0751 - val_accuracy: 0.9726\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0805 - accuracy: 0.9725 - val_loss: 0.0622 - val_accuracy: 0.9817\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.0682 - accuracy: 0.9748 - val_loss: 0.0475 - val_accuracy: 0.9817\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.0582 - accuracy: 0.9794 - val_loss: 0.0476 - val_accuracy: 0.9817\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 2s 44ms/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.0450 - val_accuracy: 0.9756\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 2s 53ms/step - loss: 0.0497 - accuracy: 0.9809 - val_loss: 0.0347 - val_accuracy: 0.9848\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 1s 31ms/step - loss: 0.0338 - accuracy: 0.9885 - val_loss: 0.0466 - val_accuracy: 0.9787\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0304 - val_accuracy: 0.9878\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0282 - accuracy: 0.9931 - val_loss: 0.0307 - val_accuracy: 0.9939\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.0306 - val_accuracy: 0.9878\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.0283 - val_accuracy: 0.9848\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.0400 - val_accuracy: 0.9848\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.0286 - val_accuracy: 0.9848\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 0.0248 - accuracy: 0.9878 - val_loss: 0.0261 - val_accuracy: 0.9909\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0250 - val_accuracy: 0.9909\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 2s 47ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 2s 41ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9909\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9909\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9909\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9939\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9939\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9939\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9939\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9939\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9939\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 2s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9909\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 2s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9939\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9939\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 9.8308e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9909\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 9.0728e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9909\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 8.6240e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9909\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 1s 31ms/step - loss: 7.7768e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9909\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 7.2398e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9909\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 6.7898e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9909\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 6.2431e-04 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9909\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 2s 43ms/step - loss: 5.9508e-04 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9909\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 2s 49ms/step - loss: 5.6107e-04 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9909\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 5.2605e-04 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9909\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 4.8882e-04 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9909\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 4.6926e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9909\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 4.4374e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9909\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 4.1546e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9878\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 4.0779e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9909\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 3.6946e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9878\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 3.6565e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9878\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 3.2853e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9878\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 2s 47ms/step - loss: 3.1877e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9878\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 2s 52ms/step - loss: 3.0295e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9878\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 2.8273e-04 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9878\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 2.7363e-04 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9878\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 2.7086e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9878\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 2.5035e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9878\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 2.4032e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9878\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 2.3251e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9878\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 1s 27ms/step - loss: 2.1845e-04 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9878\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 2.1038e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9878\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 1s 35ms/step - loss: 2.0089e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9878\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 3s 72ms/step - loss: 1.9522e-04 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9878\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 1.8137e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9909\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 1.7612e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9878\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 1.6701e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9878\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 1.6014e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9909\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 1.5249e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9878\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 1.4789e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9909\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 1.4881e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9909\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 1.3740e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9878\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 2s 38ms/step - loss: 1.3178e-04 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9909\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 2s 47ms/step - loss: 1.2949e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9878\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 2s 37ms/step - loss: 1.2042e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9878\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 1.1658e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9878\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 1.1470e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9909\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 1.1231e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9909\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 1.0599e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9909\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 1s 28ms/step - loss: 1.0175e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9909\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 9.8046e-05 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9909\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 9.5428e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9878\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 1s 32ms/step - loss: 9.1072e-05 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9909\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 2s 47ms/step - loss: 8.7899e-05 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9909\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 2s 48ms/step - loss: 8.6476e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9878\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 8.2381e-05 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9909\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 7.9515e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9939\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 1s 29ms/step - loss: 8.0445e-05 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 2s 45ms/step - loss: 7.4980e-05 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9878\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 2s 45ms/step - loss: 7.0971e-05 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9878\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 6.8359e-05 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9909\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 1s 30ms/step - loss: 6.6054e-05 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9909\n",
            "13/13 [==============================] - 1s 15ms/step\n",
            "With PCA:\n",
            "Accuracy score 0.9951219512195122\n",
            "Confusion Matrix:\n",
            "[[203   5]\n",
            " [  0 202]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       208\n",
            "           1       0.98      1.00      0.99       202\n",
            "\n",
            "    accuracy                           0.99       410\n",
            "   macro avg       0.99      0.99      0.99       410\n",
            "weighted avg       0.99      0.99      0.99       410\n",
            "\n",
            "Epoch 1/10\n",
            "41/41 [==============================] - 9s 105ms/step - loss: 0.5736 - accuracy: 0.7023 - val_loss: 0.5263 - val_accuracy: 0.7256\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 4s 107ms/step - loss: 0.4951 - accuracy: 0.7740 - val_loss: 0.4994 - val_accuracy: 0.7652\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 4s 95ms/step - loss: 0.4775 - accuracy: 0.7847 - val_loss: 0.4665 - val_accuracy: 0.7835\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 3s 83ms/step - loss: 0.4507 - accuracy: 0.8008 - val_loss: 0.4314 - val_accuracy: 0.7927\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 3s 83ms/step - loss: 0.4180 - accuracy: 0.8191 - val_loss: 0.4252 - val_accuracy: 0.7988\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 5s 121ms/step - loss: 0.3973 - accuracy: 0.8137 - val_loss: 0.3774 - val_accuracy: 0.8384\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 3s 84ms/step - loss: 0.3916 - accuracy: 0.8321 - val_loss: 0.3841 - val_accuracy: 0.8201\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 3s 81ms/step - loss: 0.3200 - accuracy: 0.8511 - val_loss: 0.4152 - val_accuracy: 0.8323\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 4s 106ms/step - loss: 0.2881 - accuracy: 0.8740 - val_loss: 0.2778 - val_accuracy: 0.8872\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 4s 102ms/step - loss: 0.2392 - accuracy: 0.8992 - val_loss: 0.2100 - val_accuracy: 0.9116\n",
            "13/13 [==============================] - 1s 21ms/step\n",
            "\n",
            "Without PCA:\n",
            "Accuracy score 0.9951219512195122\n",
            "Confusion Matrix:\n",
            "[[185  23]\n",
            " [ 20 182]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90       208\n",
            "           1       0.89      0.90      0.89       202\n",
            "\n",
            "    accuracy                           0.90       410\n",
            "   macro avg       0.90      0.90      0.90       410\n",
            "weighted avg       0.90      0.90      0.90       410\n",
            "\n"
          ]
        }
      ]
    }
  ]
}